{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Test-Deformation.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1nWptFlHxplTPQwi-irqwLgHaFKqNuz4Z","authorship_tag":"ABX9TyONkakNw08LC51mZ72TE+up"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UWQrt06UVSto"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMXMkMMZ1OxK"},"source":["!pip install tqdm\n","!pip install segmentation_models_pytorch\n","!pip install albumentations"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ze4jBsbgpKyg"},"source":["import os\n","import glob\n","import torch\n","import cv2 as cv\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from scipy.misc import electrocardiogram\n","from scipy.signal import find_peaks\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from torch.utils.data import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BSRtacK0oMJi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636471209509,"user_tz":-540,"elapsed":13,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"094dd887-14a2-4003-d5f5-ed2210435ba0"},"source":["cd drive/Shareddrives/KOHI_의료영상1팀/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/KOHI_의료영상1팀\n"]}]},{"cell_type":"code","metadata":{"id":"kxoJlFXqu1xM"},"source":["image_dir = 'Training_Data/image'\n","mask_dir = 'Training_Data/mask'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyPvVAG-0G4m"},"source":["## Load Image"]},{"cell_type":"markdown","metadata":{"id":"SSRuoUB-RnQp"},"source":["load image를 할때 cv.imread로 미리 읽어오면 메모리가 부족할 수도 있는 현상이 발생할 수도 있으므로,\n","\n","imread는 dataloader의 __getitem__에서 해결"]},{"cell_type":"code","metadata":{"id":"lzKZvo9KITwf"},"source":["input_list = os.listdir(image_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6hkgjGWpalf","executionInfo":{"status":"ok","timestamp":1636471230530,"user_tz":-540,"elapsed":15,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"cbf652cb-bd3c-4fc6-dcc6-98a5501939e9"},"source":["dataset = []\n","\n","\n","for input in tqdm(input_list):\n","  image = os.path.join(image_dir, input)\n","  label = os.path.join(mask_dir, input)\n","\n","  dataset.append({'name': input[:-4], 'image_path':image, 'label_path':label})"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2324/2324 [00:00<00:00, 221863.26it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"nb2jC_IF5Yb0"},"source":["### split train/test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7z8fkLH35XvA","executionInfo":{"status":"ok","timestamp":1636471230530,"user_tz":-540,"elapsed":12,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"a2b72842-9e72-48cd-d0a4-64d147a0cfa8"},"source":["num_train = int(len(dataset)*0.8)\n","num_rest = len(dataset)-num_train\n","\n","if num_rest % 2 == 1:\n","  num_val = int(num_rest/2)+1\n","  num_test = int(num_rest/2)\n","else:\n","  num_val = int(num_rest/2)\n","  num_test = int(num_rest/2)\n","\n","data_train = dataset[:num_train]\n","data_val = dataset[num_train:num_train+num_val]\n","data_test = dataset[num_train+num_val:]\n","print(f'train dataset 개수: {len(data_train)}, valid dataset 개수: {len(data_val)}, test dataset 개수: {len(data_test)}')\n","\n","lr = 1e-5\n","batch_size=8\n","train_continue= False\n","augment=False\n","\n","optim_mode = 'adam'\n","\n","model_sort = 'efficient'\n","\n","# ckpt_dir=f'이승아/checkpoint/U-Net/Dice/1e-05(padding)'\n","# result_dir =f'이승아/result/U-Net/Dice/1e-05(padding)'\n","\n","ckpt_dir=f'이승아/checkpoint/EfficientNet/V2'\n","result_dir =f'이승아/result/EfficientNet/V2'\n","\n","image_size = 256\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset 개수: 1859, valid dataset 개수: 233, test dataset 개수: 232\n"]}]},{"cell_type":"markdown","metadata":{"id":"gFUf7rQjJIF5"},"source":["## Augmentation"]},{"cell_type":"code","metadata":{"id":"0D8ERhw48qcd"},"source":["import albumentations as A\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMYX2TfM9F_1"},"source":["def _normalization(input):\n","  input = (input - input.min()) / (input.max() - input.min())\n","  return input\n","\n","def _standardization(input):\n","  input = (input - mean) / std\n","  return input\n","\n","def _to_tensor(input, label, name, h, w):\n","  input = input.astype('float32')\n","  label = label.astype('float32')\n","\n","  input = input.reshape((1, label.shape[0], label.shape[1]))\n","\n","  label = label.reshape((1, label.shape[0], label.shape[1]))\n","  \n","  data = {'name':name, 'input': torch.from_numpy(input), 'label': torch.from_numpy(label),\n","          'height': h, 'width': w}\n","  return data\n","\n","def _random_augment(input, label):\n","  h, w  = input.shape\n","  \n","  transform = A.Compose([A.HorizontalFlip(p=0.5),\n","                      A.VerticalFlip(p=0.5),\n","                      A.RandomCrop(height=int(h*0.8), width=int(w*0.8), p=0.5)\n","                      ]\n","                      , additional_targets={'label': 'image'})\n","\n","  augmented = transform(image=input, label=label)\n","\n","  input = augmented['image']\n","  label = augmented['label']\n","\n","  return input, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccAqrF70tcST"},"source":["## Resize by aspect ratio and Padding Image"]},{"cell_type":"code","metadata":{"id":"jwq3WIQStbEa"},"source":["def resize_image(input, label):\n","  # shape: (height, width, channel)\n","  # aspect ratio를 고려하여 resize\n","  if input.shape[1] > input.shape[0]:   # height를 기준으로\n","    r = image_size / input.shape[1]\n","    dim = ( image_size, int(input.shape[0] * r))\n","  else:                                 # width를 기준으로\n","    r = image_size / input.shape[0]\n","    dim = (int(input.shape[1] * r), image_size)\n","    \n","  resized_input = cv.resize(input, dim, interpolation = cv.INTER_AREA)\n","  resized_label = cv.resize(label, dim, interpolation = cv.INTER_NEAREST)\n","  \n","  return resized_input, resized_label\n","\n","def padding_image(input, label):\n","  input_size = input.shape\n","  target_size = (image_size, image_size)\n","\n","  if input_size[1] < image_size:\n","    padding_range = int(target_size[1]-input_size[1])\n","  elif input_size[0] < image_size:\n","    padding_range = int(target_size[0]-input_size[0])\n","  else:\n","    return input, label\n","\n","  if padding_range%2 == 0:\n","    padding_size = (int(padding_range/2), int(padding_range/2))\n","  else:\n","    padding_size = (int(padding_range/2), int(padding_range/2)+1)\n","  \n","  if input_size[1] < image_size:\n","    npad= ((0,0),padding_size)\n","  elif input_size[0] < image_size:\n","    npad= (padding_size, (0,0))\n","\n","  padding_input = np.pad(input, npad,'constant', constant_values=(0))\n","  padding_label = np.pad(label, npad,'constant', constant_values=(0))\n","\n","  return padding_input, padding_label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UM4PYZNw47T7"},"source":["## DataLoader"]},{"cell_type":"code","metadata":{"id":"U05CJ7uh27bq"},"source":["# DataLoader\n","\n","row_ratio = 0.15\n","col_ratio = 0.15\n","\n","def label_preprocessing(label):\n","  label = label/255.\n","\n","  return label\n","\n","class VertebraeDataset(Dataset):\n","\n","  def __init__(self, data, augment=False):\n","    super(VertebraeDataset, self).__init__()\n","\n","    self.data = data      \n","    self.augment = augment\n","    self.image_size = image_size\n","\n","  def __getitem__(self, index):\n","    # Read input, label\n","    name = self.data[index]['name']\n","    input = cv.imread(self.data[index]['image_path'])\n","    h, w, _ = input.shape\n","    # print(h)\n","    # print(w)\n","    try:\n","      input = cv.cvtColor(input, cv.COLOR_BGR2GRAY)    \n","    except:\n","      print(self.data[index]['image_path'])\n","      exit(-1)\n","\n","    label = cv.imread(self.data[index]['label_path'])\n","    try:\n","      label = cv.cvtColor(label, cv.COLOR_BGR2GRAY)  \n","    except:\n","      print(self.data[index]['label_path'])\n","      exit(-1)\n","    label = label/255.\n","\n","    # # 영상 개선\n","    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n","    input = clahe.apply(input)\n","    input = input / 255.0\n","    \n","    if self.augment:\n","      input, label = _random_augment(input, label)\n","      \n","    # Resize and pad Image\n","    input, label = resize_image(input, label)\n","    input, label = padding_image(input, label)\n","\n","    data = _to_tensor(input, label, name, h, w)\n","\n","    return data\n","\n","  def __len__(self):\n","    return len(self.data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sja5vP-y6Hs2"},"source":["def get_data(data, shuffle=True):\n","    ### Train Dataset 가져오기\n","    dataset = VertebraeDataset(data, augment=augment)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)  \n","\n","    return dataset, loader\n","\n","# pytorch Dataloader\n","train_dataset, train_loader = get_data(data_train)\n","val_dataset, val_loader = get_data(data_val)\n","test_dataset, test_loader = get_data(data_test, shuffle=False)\n","\n","_data = test_dataset.__getitem__(0)\n","\n","\n","# test_dataset, test_loader = get_data(data_train[:1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8QfXtubLHJT"},"source":["## Parameter 설정\n"]},{"cell_type":"code","metadata":{"id":"JqQe3tOH2Kqw"},"source":["\n","import torch.nn.functional as F\n","import segmentation_models_pytorch as smp\n","from torch import nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00eUF-si1h2J"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class DiceLoss(nn.Module):\n","    \"\"\"\n","    Dice score loss function\n","    \"\"\"\n","    def __init__(self):\n","        super(DiceLoss, self).__init__()\n","        self.smooth = 1.0\n","\n","    def forward(self, output, label):\n","        assert output.size() == label.size()\n","        output = output[:, 0].contiguous().view(-1)\n","        label = label[:, 0].contiguous().view(-1)\n","        intersection = (output * label).sum()\n","        dsc = (2. * intersection + self.smooth) / (output.sum() + label.sum() + self.smooth)\n","\n","        return 1. - dsc\n","\n","\n","class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceBCELoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        # comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = torch.sigmoid(inputs)\n","\n","        # flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice_loss = 1 - (2. * intersection + smooth) /(inputs.sum() + targets.sum() + smooth)\n","        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","\n","        return Dice_BCE\n","\n","class Binary_Loss(nn.Module):\n","    def __init__(self):\n","        super(Binary_Loss, self).__init__()\n","        self.criterion = nn.BCEWithLogitsLoss()\n","\n","\n","    def forward(self, model_output, targets):\n","        loss = self.criterion(model_output, targets)\n","\n","       \n","        return loss\n","\n","bcedice_loss = DiceBCELoss().cuda()\n","binary_loss = Binary_Loss().cuda()\n","dsc_loss = DiceLoss().cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9zjD6UidJJpi"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"t7Ml0exeJLqf"},"source":["from segmentation_models_pytorch.unet.model import Unet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1LCPAOMgY8ac","executionInfo":{"status":"ok","timestamp":1636471244504,"user_tz":-540,"elapsed":10453,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"13d3310d-e0bc-4df1-9145-eebf9109567d"},"source":["from collections import OrderedDict\n","\n","if model_sort == 'unet':\n","  class UNet(nn.Module):\n","\n","      def __init__(self, in_channels=1, out_channels=1, init_features=32):\n","          super(UNet, self).__init__()\n","\n","          features = init_features\n","          self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n","          self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","          self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n","          self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","          self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n","          self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","          self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n","          self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","          self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n","\n","          self.upconv4 = nn.ConvTranspose2d(\n","              features * 16, features * 8, kernel_size=2, stride=2\n","          )\n","          self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n","          self.upconv3 = nn.ConvTranspose2d(\n","              features * 8, features * 4, kernel_size=2, stride=2\n","          )\n","          self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n","          self.upconv2 = nn.ConvTranspose2d(\n","              features * 4, features * 2, kernel_size=2, stride=2\n","          )\n","          self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n","          self.upconv1 = nn.ConvTranspose2d(\n","              features * 2, features, kernel_size=2, stride=2\n","          )\n","          self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n","\n","          self.conv = nn.Conv2d(\n","              in_channels=features, out_channels=out_channels, kernel_size=1\n","          )\n","\n","      def forward(self, x):\n","          enc1 = self.encoder1(x)\n","          enc2 = self.encoder2(self.pool1(enc1))\n","          enc3 = self.encoder3(self.pool2(enc2))\n","          enc4 = self.encoder4(self.pool3(enc3))\n","\n","          bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","          dec4 = self.upconv4(bottleneck)\n","          dec4 = torch.cat((dec4, enc4), dim=1)\n","          dec4 = self.decoder4(dec4)\n","          dec3 = self.upconv3(dec4)\n","          dec3 = torch.cat((dec3, enc3), dim=1)\n","          dec3 = self.decoder3(dec3)\n","          dec2 = self.upconv2(dec3)\n","          dec2 = torch.cat((dec2, enc2), dim=1)\n","          dec2 = self.decoder2(dec2)\n","          dec1 = self.upconv1(dec2)\n","          dec1 = torch.cat((dec1, enc1), dim=1)\n","          dec1 = self.decoder1(dec1)\n","          return torch.sigmoid(self.conv(dec1))\n","\n","      @staticmethod\n","      def _block(in_channels, features, name):\n","          return nn.Sequential(\n","              OrderedDict(\n","                  [\n","                      (\n","                          name + \"conv1\",\n","                          nn.Conv2d(\n","                              in_channels=in_channels,\n","                              out_channels=features,\n","                              kernel_size=3,\n","                              padding=1,\n","                              bias=False,\n","                          ),\n","                      ),\n","                      (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n","                      (name + \"relu1\", nn.ReLU(inplace=True)),\n","                      (\n","                          name + \"conv2\",\n","                          nn.Conv2d(\n","                              in_channels=features,\n","                              out_channels=features,\n","                              kernel_size=3,\n","                              padding=1,\n","                              bias=False,\n","                          ),\n","                      ),\n","                      (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n","                      (name + \"relu2\", nn.ReLU(inplace=True)),\n","                  ]\n","              )\n","          )\n","  model = UNet().to(device)\n","  print('unet')\n","else:\n","  model = Unet(\n","    encoder_name=\"efficientnet-b5\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n","    encoder_weights=None,     # use `imagenet` pre-trained weights for encoder initialization\n","    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n","    classes=1,).to(device)\n","  print('efficient')\n","\n","# Optimizer Adam 설정\n","if optim_mode == 'adam':\n","  optim = torch.optim.Adam(model.parameters(), lr=lr)\n","elif optim_mode == 'sgd':\n","  optim = torch.optim.SGD(model.parameters(), lr=lr)\n","elif optim_mode == 'adamW':\n","  optim = torch.optim.Adam(model.parameters(), lr=lr)\n","print(optim_mode)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["efficient\n","adam\n"]}]},{"cell_type":"code","metadata":{"id":"O3A2ecqdPuUt"},"source":["fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)  # Tensor를 numpy로 변환\n","fn_denorm = lambda x, mean, std: (x * std) + mean  # DeNomarlization\n","fn_class = lambda x: 1.0 * (x > 0.4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6Jy2ctTXEv_"},"source":["def load_model(ckpt_dir, model, optim):\n","    if not os.path.exists(ckpt_dir):\n","        epoch = 0\n","        return model\n","\n","    ckpt_lst = os.listdir(ckpt_dir)\n","    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n","    print(os.path.join(ckpt_dir, ckpt_lst[-1]))\n","\n","    dict_model = torch.load(os.path.join(ckpt_dir, ckpt_lst[-1]))\n","    model.load_state_dict(dict_model['model'], strict=False)\n","    optim.load_state_dict(dict_model['optim'])\n","    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n","    print(\"Get saved weights successfully.\")\n","\n","    return model, optim, epoch\n","\n","def save_model(ckpt_dir, model, optim, epoch):\n","    if not os.path.exists(ckpt_dir):\n","        os.makedirs(ckpt_dir)\n","\n","    torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n","                \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n","    print(f'>> save model_{epoch}.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxAdDAPKYbO0"},"source":["# Test"]},{"cell_type":"code","metadata":{"id":"h_i-iyqjXUa7"},"source":["def numeric_score(output, label):\n","    FP = np.float(np.sum((output == 1) & (label == 0)))\n","    FN = np.float(np.sum((output == 0) & (label == 1)))\n","    if FP != 0.0 or FN != 0.0:\n","        pass\n","    TP = np.float(np.sum((output == 1) & (label == 1)))\n","    TN = np.float(np.sum((output == 0) & (label == 0)))\n","\n","    return FP, FN, TP, TN\n","\n","def get_score(output, label):\n","    FP, FN, TP, TN = numeric_score(output, label)\n","    N = FP + FN + TP + TN\n","\n","    epsilon = 1e-5\n","\n","    # Recall : TP / TP+FN\n","    recall = np.divide(TP, TP + FN + epsilon)\n","    # Precision : TP / TP+FP\n","    precision = np.divide(TP, (TP+FP+epsilon))\n","\n","    accuracy = np.divide((TP + TN), N+epsilon)\n","\n","    # F1 socre = 2 * (A interect B) / |A| + |B| = 2TP / 2TP + FP + FN\n","    f1_score = 2 * (precision*recall) / (precision + recall + epsilon)\n","    dice_coeff = 2*TP / (2*TP+FP+FN+epsilon)\n","\n","    # J(A,B) = | A intersect B | / | A union B |\n","    jaccard_score = TP / (TP+FN+FP+ epsilon)\n","\n","    return recall * 100, precision * 100, accuracy * 100, f1_score*100, jaccard_score*100\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cCQ0t1s479rS"},"source":["def save_predictedMask(input, label, output, name):\n","    for idx in range(label.shape[0]):\n","        file_name = name[idx]\n","        plt.figure(figsize=(21, 7))  \n","        plt.subplot(131)\n","        plt.imshow(input[idx].astype('uint8').squeeze(), cmap='gray')\n","        plt.title('input')\n","\n","        plt.subplot(132)\n","        plt.imshow(label[idx].squeeze(), cmap='gray')\n","        plt.title('label')\n","\n","        plt.subplot(133)    \n","        plt.imshow(output[idx].squeeze(), cmap='gray')\n","        plt.title('output')\n","        \n","        # plt.show()\n","        plt.axis('off'), plt.xticks([]), plt.yticks([])\n","        plt.tight_layout()\n","        plt.savefig(os.path.join(result_dir, f'{file_name}.png'), pad_inches=0.1)\n","        plt.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"IkFoH0nJdnc9","executionInfo":{"status":"ok","timestamp":1636471244506,"user_tz":-540,"elapsed":17,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"ba7da907-c572-4fdf-89e7-a6ec5dacc59f"},"source":["result_dir"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'이승아/result/EfficientNet/V2'"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"MPXck0Vmo_sJ"},"source":["import copy\n","\n","def metric(gt,pred):\n","    preds = pred.detach().numpy()\n","    gts = gt.detach().numpy()\n","\n","    pred = preds.astype(int)  # float data does not support bit_and and bit_or\n","    gdth = gts.astype(int)  # float data does not support bit_and and bit_or\n","    fp_array = copy.deepcopy(pred)  # keep pred unchanged\n","    fn_array = copy.deepcopy(gdth)\n","    gdth_sum = np.sum(gdth)\n","    pred_sum = np.sum(pred)\n","    intersection = gdth & pred\n","    union = gdth | pred\n","    intersection_sum = np.count_nonzero(intersection)\n","    union_sum = np.count_nonzero(union)\n","\n","    tp_array = intersection\n","\n","    tmp = pred - gdth\n","    fp_array[tmp < 1] = 0\n","\n","    tmp2 = gdth - pred\n","    fn_array[tmp2 < 1] = 0\n","\n","    tn_array = np.ones(gdth.shape) - union\n","\n","    tp, fp, fn, tn = np.sum(tp_array), np.sum(fp_array), np.sum(fn_array), np.sum(tn_array)\n","\n","    smooth = 0.001\n","    precision = tp / (pred_sum + smooth)\n","    recall = tp / (gdth_sum + smooth)\n","\n","    false_positive_rate = fp / (fp + tn + smooth)\n","    false_negtive_rate = fn / (fn + tp + smooth)\n","\n","    jaccard = intersection_sum / (union_sum + smooth)\n","    dice = 2 * intersection_sum / (gdth_sum + pred_sum + smooth)\n","    \n","    epsilon = 1e-5\n","    f1_score = 2 * (precision*recall) / (precision + recall + epsilon)\n","\n","    return false_positive_rate,false_negtive_rate,f1_score\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBQ_Qrw98HGS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636471793053,"user_tz":-540,"elapsed":470570,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"b89d288b-9a96-48c9-eb2a-2841cd86fce2"},"source":["st_epoch=0\n","\n","model, optim, st_epoch = load_model(ckpt_dir=ckpt_dir, model=model, optim=optim)\n","\n","with torch.no_grad():\n","    model.eval()\n","\n","    loss_arr = []\n","    total_recall = []\n","    total_precision = []\n","    total_f1_score = []\n","    total_jaccard = []\n","\n","    for iter, data in enumerate(tqdm(test_loader), 1):\n","        name = data['name']\n","        input = data['input'].to(device)\n","        label = data['label'].to(device)\n","        \n","        output = model(input)\n","\n","        if model_sort == 'unet':\n","          loss = dsc_loss(output, label)\n","          \n","          # for metrics\n","          output[output>0.5] = 1\n","          output[output<=0.5] = 0\n","          \n","        else:\n","          loss = bcedice_loss(output, label)\n","          loss_arr += [loss.item()]\n","      \n","          # for metrics\n","          logit = torch.sigmoid(output)\n","          output = logit.clone()\n","          output[output>0.5] = 1\n","          output[output<=0.5] = 0\n","\n","        false_positive_rate,false_negtive_rate,f1_score = metric(label.cpu(), output.cpu())\n","        \n","        label = fn_tonumpy(label)\n","        input = fn_tonumpy(input*255)\n","        output = fn_tonumpy(output)\n","        \n","        save_predictedMask(input, label, output, name)\n","\n","\n","#         print(\"AVERAGE TEST: BATCH %04d / %04d | LOSS %.4f\" % (iter, num_batch_test, np.mean(loss_arr)))\n","\n","# print(\"\\nTEST: BATCH %04d / %04d | LOSS %.4f\" % (iter, num_batch_test, np.mean(loss_arr)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이승아/checkpoint/EfficientNet/V2/model_epoch200.pth\n","Get saved weights successfully.\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 29/29 [07:49<00:00, 16.19s/it]\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ki8Y2LrjooXV"},"source":["# Save final output\n"]},{"cell_type":"code","metadata":{"id":"Ftz-iFJ5qPUt"},"source":["result_dir = './result/PadChest/mask'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-fqnCL1pFDr"},"source":["def save_final_output(name, output, origin_height, origin_width):\n","    output *= 255\n","    for idx in range(label.shape[0]):\n","        file_name = name[idx]\n","\n","        h = origin_height[idx]\n","        w = origin_width[idx]\n","        dim = (w, h)\n","\n","        _output = output[idx].squeeze()\n","        # _output = cv.resize(_output, dim, interpolation = cv.INTER_NEAREST)\n","        \n","        cv.imwrite(os.path.join(result_dir, file_name+'.png'), _output)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_XEkTakpDhH","colab":{"base_uri":"https://localhost:8080/","height":440},"executionInfo":{"status":"error","timestamp":1636455783577,"user_tz":-540,"elapsed":60309,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"8a604c24-ee0f-4cd9-a086-c643f9836fa9"},"source":["st_epoch=0\n","\n","model, optim, st_epoch = load_model(ckpt_dir=ckpt_dir, model=model, optim=optim)\n","\n","with torch.no_grad():\n","    model.eval()\n","\n","    loss_arr = []\n","    total_recall = []\n","    total_precision = []\n","    total_f1_score = []\n","    total_jaccard = []\n","\n","    for iter, data in enumerate(tqdm(test_loader), 1):\n","        name = data['name']\n","\n","        origin_height = data['height']\n","        origin_width = data['width']\n","\n","        input = data['input'].to(device)\n","        label = data['label'].to(device)\n","\n","        output = model(input)\n","\n","        loss = bcedice_loss(output, label)\n","        loss_arr += [loss.item()]\n","\n","        # for metrics\n","        logit = torch.sigmoid(output)\n","        output = logit.clone()\n","        output[output>0.5] = 1\n","        output[output<=0.5] = 0\n","\n","        # draw_ROC_curve(output, label)\n","        # recall, precision, accuracy, f1_score, jaccard = get_score(output, label)\n","        false_positive_rate,false_negtive_rate,f1_score = metric(label.cpu(), output.cpu())\n","        \n","        label = fn_tonumpy(label)\n","        input = fn_tonumpy(input*255)\n","        output = fn_tonumpy(output)\n","\n","        save_final_output(name, output, origin_height, origin_width)\n","        \n","        # save_predictedMask(input, label, output, iter)\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["이승아/checkpoint/EfficientNet/V2/model_epoch150.pth\n","Get saved weights successfully.\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 6/29 [00:55<03:33,  9.27s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-74f9eec5d3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtotal_jaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-57ab390fec15>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"8tWgv4Q7_jEs"},"source":["len(os.listdir(result_dir))"],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train/Valid-UNet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Bt8IcFXA7jjB-BAVH6B89lfcXnZ6GHNm","authorship_tag":"ABX9TyN656DGxeNUI1qWQe6oi8w/"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wLVM9qEB9qub","executionInfo":{"status":"ok","timestamp":1636043047536,"user_tz":-540,"elapsed":1115,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"e35a911d-b845-4902-8fdc-2d2426c57614"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"NMXMkMMZ1OxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636123130472,"user_tz":-540,"elapsed":19612,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"a891ce99-b311-4b3c-bdbd-86c7174045ca"},"source":["!pip install tqdm\n","!pip install segmentation_models_pytorch\n","!pip install albumentations\n","!pip install wandb"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n","Collecting segmentation_models_pytorch\n","  Downloading segmentation_models_pytorch-0.2.0-py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 7.3 MB/s \n","\u001b[?25hCollecting pretrainedmodels==0.7.4\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 8.2 MB/s \n","\u001b[?25hCollecting efficientnet-pytorch==0.6.3\n","  Downloading efficientnet_pytorch-0.6.3.tar.gz (16 kB)\n","Collecting timm==0.4.12\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[K     |████████████████████████████████| 376 kB 48.7 MB/s \n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from segmentation_models_pytorch) (0.10.0+cu111)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.9.0+cu111)\n","Collecting munch\n","  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.62.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (3.7.4.3)\n","Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.15.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-py3-none-any.whl size=12421 sha256=cfdb680b61c947ecd3c94cf41abcb9d693c182e94ed361e81c0d34c6dfdf349c\n","  Stored in directory: /root/.cache/pip/wheels/90/6b/0c/f0ad36d00310e65390b0d4c9218ae6250ac579c92540c9097a\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=ef90bd0fb5a8310e8f678a733348c06eb86f1b0394b355941390d06c5fecd7ab\n","  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: munch, timm, pretrainedmodels, efficientnet-pytorch, segmentation-models-pytorch\n","Successfully installed efficientnet-pytorch-0.6.3 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.2.0 timm-0.4.12\n","Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (0.1.12)\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.19.5)\n","Collecting imgaug<0.2.7,>=0.2.5\n","  Downloading imgaug-0.2.6.tar.gz (631 kB)\n","\u001b[K     |████████████████████████████████| 631 kB 25.7 MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from albumentations) (4.1.2.30)\n","Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (0.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug<0.2.7,>=0.2.5->albumentations) (1.15.0)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (3.2.2)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.1.1)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.6.3)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (7.1.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations) (0.10.0)\n","Building wheels for collected packages: imgaug\n","  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654020 sha256=69815e14e2f7dc8a728acced6825e924e030b5468b1ef6cb2e09f43f98b9950e\n","  Stored in directory: /root/.cache/pip/wheels/89/72/98/3ebfdba1069a9a8eaaa7ae7265cfd67d63ef0197aaee2e5f9c\n","Successfully built imgaug\n","Installing collected packages: imgaug\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","Successfully installed imgaug-0.2.6\n","Collecting wandb\n","  Downloading wandb-0.12.6-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 23.9 MB/s \n","\u001b[?25hCollecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n","Collecting configparser>=3.8.1\n","  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Collecting subprocess32>=3.5.3\n","  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n","\u001b[K     |████████████████████████████████| 97 kB 7.7 MB/s \n","\u001b[?25hCollecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n","\u001b[K     |████████████████████████████████| 139 kB 64.9 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Collecting yaspin>=1.0.0\n","  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Collecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n","\u001b[K     |████████████████████████████████| 180 kB 63.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n","Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n","Building wheels for collected packages: subprocess32, pathtools\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=ea177668b8aa31559e23e06ca8641e0b52e9f0e92a911f7260f8c0910d8c5358\n","  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=ee43f34ed8af817ffd5bf6197774874ad6670e2752e850fe4149175e1cef26b2\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built subprocess32 pathtools\n","Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb\n","Successfully installed GitPython-3.1.24 configparser-5.1.0 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.6 yaspin-2.1.0\n"]}]},{"cell_type":"code","metadata":{"id":"Ze4jBsbgpKyg"},"source":["import os\n","import glob\n","import torch\n","import cv2 as cv\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","from scipy.misc import electrocardiogram\n","from scipy.signal import find_peaks\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from torch.utils.data import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSRtacK0oMJi","executionInfo":{"status":"ok","timestamp":1636123143862,"user_tz":-540,"elapsed":11,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"eac2abd8-5363-497d-e15d-4e61029e4b3d"},"source":["cd drive/Shareddrives/KOHI_의료영상1팀/"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/Shareddrives/KOHI_의료영상1팀\n"]}]},{"cell_type":"code","metadata":{"id":"EgVogGwmo8X9"},"source":["image_dir = 'Training_Data/image'\n","mask_dir = 'Training_Data/mask'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YyPvVAG-0G4m"},"source":["## Load Image"]},{"cell_type":"markdown","metadata":{"id":"SSRuoUB-RnQp"},"source":["load image를 할때 cv.imread로 미리 읽어오면 메모리가 부족할 수도 있는 현상이 발생할 수도 있으므로,\n","\n","imread는 dataloader의 __getitem__에서 해결"]},{"cell_type":"code","metadata":{"id":"fQQGlgQutNTk"},"source":["input_list = os.listdir(image_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MfNIYdWtbZD","executionInfo":{"status":"ok","timestamp":1636123158630,"user_tz":-540,"elapsed":11,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"cce3a272-296e-4029-9675-a65beb2faecf"},"source":["len(input_list)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2324"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6hkgjGWpalf","executionInfo":{"status":"ok","timestamp":1636123158630,"user_tz":-540,"elapsed":3,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"e0af47f8-e24d-4304-b7fe-68662e9c4d96"},"source":["dataset = []\n","\n","for input in tqdm(input_list):\n","  image = os.path.join(image_dir, input)\n","  label = os.path.join(mask_dir, input)\n","\n","  dataset.append({'name': input[:-4], 'image_path':image, 'label_path':label})"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2324/2324 [00:00<00:00, 141696.16it/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"nb2jC_IF5Yb0"},"source":["### split train/test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7z8fkLH35XvA","executionInfo":{"status":"ok","timestamp":1636123159892,"user_tz":-540,"elapsed":1264,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"78c5362f-98f9-4a1e-b1f9-c27808e97efd"},"source":["num_train = int(len(dataset)*0.8)\n","num_rest = len(dataset)-num_train\n","\n","if num_rest % 2 == 1:\n","  num_val = int(num_rest/2)+1\n","  num_test = int(num_rest/2)\n","else:\n","  num_val = int(num_rest/2)\n","  num_test = int(num_rest/2)\n","\n","data_train = dataset[:num_train]\n","data_val = dataset[num_train:num_train+num_val]\n","data_test = dataset[num_train+num_val:]\n","print(f'train dataset 개수: {len(data_train)}, valid dataset 개수: {len(data_val)}, test dataset 개수: {len(data_test)}')\n","\n","lr = 1e-5\n","batch_size=8\n","train_continue= False\n","augment=True\n","image_size=256\n","\n","optim_mode = 'adam'\n","\n","ckpt_dir=f'이승아/checkpoint/U-Net/Dice/{lr}(padding)'\n","if not os.path.isdir(ckpt_dir):\n","    os.mkdir(ckpt_dir)\n","\n","result_dir =f'이승아/result/U-Net/Dice/{lr}(padding)'\n","if not os.path.isdir(result_dir):\n","    os.mkdir(result_dir)\n","\n","image_size = 256\n","\n","num_epoch = 100\n","\n","num_batch_train = np.ceil(num_train / batch_size)  \n","num_batch_train = np.ceil(num_val / batch_size)  \n","num_batch_test = np.ceil(num_test / batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train dataset 개수: 1859, valid dataset 개수: 233, test dataset 개수: 232\n"]}]},{"cell_type":"markdown","metadata":{"id":"gFUf7rQjJIF5"},"source":["## Augmentation"]},{"cell_type":"code","metadata":{"id":"0D8ERhw48qcd"},"source":["import albumentations as A\n","from torch.utils.data import DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMYX2TfM9F_1"},"source":["def _normalization(input):\n","  input = (input - input.min()) / (input.max() - input.min())\n","  return input\n","\n","def _standardization(input):\n","  input = (input - mean) / std\n","  return input\n","\n","def _to_tensor(input, label, name):\n","  input = input.astype('float32')\n","  label = label.astype('float32')\n","\n","  input = input.reshape((1, label.shape[0], label.shape[1]))\n","\n","  label = label.reshape((1, label.shape[0], label.shape[1]))\n","  \n","  data = {'name':name, 'input': torch.from_numpy(input), 'label': torch.from_numpy(label)}\n","  return data\n","\n","def _random_augment(input, label):\n","  h, w  = input.shape\n","  \n","  transform = A.Compose([A.HorizontalFlip(p=0.5),\n","                      A.VerticalFlip(p=0.5),\n","                      A.RandomCrop(height=int(h*0.8), width=int(w*0.8), p=0.5)\n","                      ]\n","                      , additional_targets={'label': 'image'})\n","\n","  augmented = transform(image=input, label=label)\n","\n","  input = augmented['image']\n","  label = augmented['label']\n","\n","  return input, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UM4PYZNw47T7"},"source":["## DataLoader"]},{"cell_type":"code","metadata":{"id":"wF4RaoNcwtj_"},"source":["def resize_image(input, label):\n","  # shape: (height, width, channel)\n","  # aspect ratio를 고려하여 resize\n","  if input.shape[1] > input.shape[0]:   # height를 기준으로\n","    r = image_size / input.shape[1]\n","    dim = ( image_size, int(input.shape[0] * r))\n","  else:                                 # width를 기준으로\n","    r = image_size / input.shape[0]\n","    dim = (int(input.shape[1] * r), image_size)\n","    \n","  resized_input = cv.resize(input, dim, interpolation = cv.INTER_AREA)\n","  resized_label = cv.resize(label, dim, interpolation = cv.INTER_NEAREST)\n","  \n","  return resized_input, resized_label\n","\n","def padding_image(input, label):\n","  input_size = input.shape\n","  target_size = (image_size, image_size)\n","\n","  if input_size[1] < image_size:\n","    padding_range = int(target_size[1]-input_size[1])\n","  elif input_size[0] < image_size:\n","    padding_range = int(target_size[0]-input_size[0])\n","  else:\n","    return input, label\n","\n","  if padding_range%2 == 0:\n","    padding_size = (int(padding_range/2), int(padding_range/2))\n","  else:\n","    padding_size = (int(padding_range/2), int(padding_range/2)+1)\n","  \n","  if input_size[1] < image_size:\n","    npad= ((0,0),padding_size)\n","  elif input_size[0] < image_size:\n","    npad= (padding_size, (0,0))\n","\n","  padding_input = np.pad(input, npad,'constant', constant_values=(0))\n","  padding_label = np.pad(label, npad,'constant', constant_values=(0))\n","\n","  return padding_input, padding_label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U05CJ7uh27bq"},"source":["# DataLoader\n","\n","row_ratio = 0.15\n","col_ratio = 0.15\n","\n","def label_preprocessing(label):\n","  label = label/255.\n","\n","  return label\n","\n","class VertebraeDataset(Dataset):\n","\n","  def __init__(self, data, augment=False):\n","    super(VertebraeDataset, self).__init__()\n","\n","    self.data = data      \n","    self.augment = augment\n","    self.image_size = image_size\n","\n","  def __getitem__(self, index):\n","    # Read input, label\n","    name = self.data[index]['name']\n","    input = cv.imread(self.data[index]['image_path'])\n","    try:\n","      input = cv.cvtColor(input, cv.COLOR_BGR2GRAY)\n","    except:\n","      print(self.data[index]['image_path'])\n","      exit(-1)\n","\n","    label = cv.imread(self.data[index]['label_path'])\n","    try:\n","      label = cv.cvtColor(label, cv.COLOR_BGR2GRAY)  \n","    except:\n","      print(self.data[index]['label_path'])\n","      exit(-1)\n","    label = label/255.\n","\n","    # # 영상 개선\n","    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))\n","    input = clahe.apply(input)\n","    \n","    input = input / 255.0\n","    \n","    if self.augment:\n","      input, label = _random_augment(input, label)\n","      \n","    # Resize and pad Image\n","    input, label = resize_image(input, label)\n","    input, label = padding_image(input, label)\n","\n","    data = _to_tensor(input, label, name)\n","\n","    return data\n","\n","  def __len__(self):\n","    return len(self.data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sja5vP-y6Hs2"},"source":["def get_data(data):\n","    ### Train Dataset 가져오기\n","    dataset = VertebraeDataset(data, augment=augment)\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)  \n","\n","    return dataset, loader\n","\n","# pytorch Dataloader\n","train_dataset, train_loader = get_data(data_train)\n","val_dataset, val_loader = get_data(data_val)\n","test_dataset, test_loader = get_data(data_test)\n","\n","_data = test_dataset.__getitem__(1)\n","\n","# test_dataset, test_loader = get_data(data_train[:1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8QfXtubLHJT"},"source":["## Parameter 설정\n"]},{"cell_type":"code","metadata":{"id":"JqQe3tOH2Kqw"},"source":["import segmentation_models_pytorch as smp\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import StepLR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"00eUF-si1h2J"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","class DiceLoss(nn.Module):\n","    \"\"\"\n","    Dice score loss function\n","    \"\"\"\n","    def __init__(self):\n","        super(DiceLoss, self).__init__()\n","        self.smooth = 1.0\n","\n","    def forward(self, output, label):\n","        assert output.size() == label.size()\n","        output = output[:, 0].contiguous().view(-1)\n","        label = label[:, 0].contiguous().view(-1)\n","        intersection = (output * label).sum()\n","        dsc = (2. * intersection + self.smooth) / (output.sum() + label.sum() + self.smooth)\n","\n","        return 1. - dsc\n","\n","\n","class DiceBCELoss(nn.Module):\n","    def __init__(self, weight=None, size_average=True):\n","        super(DiceBCELoss, self).__init__()\n","\n","    def forward(self, inputs, targets, smooth=1):\n","\n","        # comment out if your model contains a sigmoid or equivalent activation layer\n","        inputs = torch.sigmoid(inputs)\n","\n","        # flatten label and prediction tensors\n","        inputs = inputs.view(-1)\n","        targets = targets.view(-1)\n","\n","        intersection = (inputs * targets).sum()\n","        dice_loss = 1 - (2. * intersection + smooth) /(inputs.sum() + targets.sum() + smooth)\n","        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n","        Dice_BCE = BCE + dice_loss\n","\n","        return Dice_BCE\n","\n","class Binary_Loss(nn.Module):\n","    def __init__(self):\n","        super(Binary_Loss, self).__init__()\n","        self.criterion = nn.BCEWithLogitsLoss()\n","\n","\n","    def forward(self, model_output, targets):\n","        loss = self.criterion(model_output, targets)\n","\n","       \n","        return loss\n","\n","bcedice_loss = DiceBCELoss().cuda()\n","binary_loss = Binary_Loss().cuda()\n","dsc_loss = DiceLoss().cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rAcLaj6c1i5J"},"source":["## Build Model"]},{"cell_type":"code","metadata":{"id":"Ez8h0hkxWKxv"},"source":["from segmentation_models_pytorch.unet.model import Unet"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W5_Tz1SRcGP9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636123581378,"user_tz":-540,"elapsed":10149,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"3653b017-d038-4bda-e0f3-7b9de61b7436"},"source":["from collections import OrderedDict\n","\n","## 네트워크 구축하기\n","class UNet(nn.Module):\n","\n","    def __init__(self, in_channels=1, out_channels=1, init_features=32):\n","        super(UNet, self).__init__()\n","\n","        features = init_features\n","        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n","\n","        self.upconv4 = nn.ConvTranspose2d(\n","            features * 16, features * 8, kernel_size=2, stride=2\n","        )\n","        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n","        self.upconv3 = nn.ConvTranspose2d(\n","            features * 8, features * 4, kernel_size=2, stride=2\n","        )\n","        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n","        self.upconv2 = nn.ConvTranspose2d(\n","            features * 4, features * 2, kernel_size=2, stride=2\n","        )\n","        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n","        self.upconv1 = nn.ConvTranspose2d(\n","            features * 2, features, kernel_size=2, stride=2\n","        )\n","        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n","\n","        self.conv = nn.Conv2d(\n","            in_channels=features, out_channels=out_channels, kernel_size=1\n","        )\n","\n","    def forward(self, x):\n","        enc1 = self.encoder1(x)\n","        enc2 = self.encoder2(self.pool1(enc1))\n","        enc3 = self.encoder3(self.pool2(enc2))\n","        enc4 = self.encoder4(self.pool3(enc3))\n","\n","        bottleneck = self.bottleneck(self.pool4(enc4))\n","\n","        dec4 = self.upconv4(bottleneck)\n","        dec4 = torch.cat((dec4, enc4), dim=1)\n","        dec4 = self.decoder4(dec4)\n","        dec3 = self.upconv3(dec4)\n","        dec3 = torch.cat((dec3, enc3), dim=1)\n","        dec3 = self.decoder3(dec3)\n","        dec2 = self.upconv2(dec3)\n","        dec2 = torch.cat((dec2, enc2), dim=1)\n","        dec2 = self.decoder2(dec2)\n","        dec1 = self.upconv1(dec2)\n","        dec1 = torch.cat((dec1, enc1), dim=1)\n","        dec1 = self.decoder1(dec1)\n","        return torch.sigmoid(self.conv(dec1))\n","\n","    @staticmethod\n","    def _block(in_channels, features, name):\n","        return nn.Sequential(\n","            OrderedDict(\n","                [\n","                    (\n","                        name + \"conv1\",\n","                        nn.Conv2d(\n","                            in_channels=in_channels,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu1\", nn.ReLU(inplace=True)),\n","                    (\n","                        name + \"conv2\",\n","                        nn.Conv2d(\n","                            in_channels=features,\n","                            out_channels=features,\n","                            kernel_size=3,\n","                            padding=1,\n","                            bias=False,\n","                        ),\n","                    ),\n","                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n","                    (name + \"relu2\", nn.ReLU(inplace=True)),\n","                ]\n","            )\n","        )\n","\n","model = UNet().to(device)\n","\n","# Optimizer Adam 설정\n","if optim_mode == 'adam':\n","  optim = torch.optim.Adam(model.parameters(), lr=lr)\n","elif optim_mode == 'sgd':\n","  optim = torch.optim.SGD(model.parameters(), lr=lr)\n","elif optim_mode == 'adamW':\n","  optim = torch.optim.Adam(model.parameters(), lr=lr)\n","print(optim_mode)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["adam\n"]}]},{"cell_type":"code","metadata":{"id":"V6yNMtCqP06s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636123582022,"user_tz":-540,"elapsed":654,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"d08bb66d-be94-4297-ca29-fd11c52460b9"},"source":["from torchsummary import summary\n","\n","print(summary(model, (1, image_size, image_size)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 32, 256, 256]             288\n","       BatchNorm2d-2         [-1, 32, 256, 256]              64\n","              ReLU-3         [-1, 32, 256, 256]               0\n","            Conv2d-4         [-1, 32, 256, 256]           9,216\n","       BatchNorm2d-5         [-1, 32, 256, 256]              64\n","              ReLU-6         [-1, 32, 256, 256]               0\n","         MaxPool2d-7         [-1, 32, 128, 128]               0\n","            Conv2d-8         [-1, 64, 128, 128]          18,432\n","       BatchNorm2d-9         [-1, 64, 128, 128]             128\n","             ReLU-10         [-1, 64, 128, 128]               0\n","           Conv2d-11         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-12         [-1, 64, 128, 128]             128\n","             ReLU-13         [-1, 64, 128, 128]               0\n","        MaxPool2d-14           [-1, 64, 64, 64]               0\n","           Conv2d-15          [-1, 128, 64, 64]          73,728\n","      BatchNorm2d-16          [-1, 128, 64, 64]             256\n","             ReLU-17          [-1, 128, 64, 64]               0\n","           Conv2d-18          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-19          [-1, 128, 64, 64]             256\n","             ReLU-20          [-1, 128, 64, 64]               0\n","        MaxPool2d-21          [-1, 128, 32, 32]               0\n","           Conv2d-22          [-1, 256, 32, 32]         294,912\n","      BatchNorm2d-23          [-1, 256, 32, 32]             512\n","             ReLU-24          [-1, 256, 32, 32]               0\n","           Conv2d-25          [-1, 256, 32, 32]         589,824\n","      BatchNorm2d-26          [-1, 256, 32, 32]             512\n","             ReLU-27          [-1, 256, 32, 32]               0\n","        MaxPool2d-28          [-1, 256, 16, 16]               0\n","           Conv2d-29          [-1, 512, 16, 16]       1,179,648\n","      BatchNorm2d-30          [-1, 512, 16, 16]           1,024\n","             ReLU-31          [-1, 512, 16, 16]               0\n","           Conv2d-32          [-1, 512, 16, 16]       2,359,296\n","      BatchNorm2d-33          [-1, 512, 16, 16]           1,024\n","             ReLU-34          [-1, 512, 16, 16]               0\n","  ConvTranspose2d-35          [-1, 256, 32, 32]         524,544\n","           Conv2d-36          [-1, 256, 32, 32]       1,179,648\n","      BatchNorm2d-37          [-1, 256, 32, 32]             512\n","             ReLU-38          [-1, 256, 32, 32]               0\n","           Conv2d-39          [-1, 256, 32, 32]         589,824\n","      BatchNorm2d-40          [-1, 256, 32, 32]             512\n","             ReLU-41          [-1, 256, 32, 32]               0\n","  ConvTranspose2d-42          [-1, 128, 64, 64]         131,200\n","           Conv2d-43          [-1, 128, 64, 64]         294,912\n","      BatchNorm2d-44          [-1, 128, 64, 64]             256\n","             ReLU-45          [-1, 128, 64, 64]               0\n","           Conv2d-46          [-1, 128, 64, 64]         147,456\n","      BatchNorm2d-47          [-1, 128, 64, 64]             256\n","             ReLU-48          [-1, 128, 64, 64]               0\n","  ConvTranspose2d-49         [-1, 64, 128, 128]          32,832\n","           Conv2d-50         [-1, 64, 128, 128]          73,728\n","      BatchNorm2d-51         [-1, 64, 128, 128]             128\n","             ReLU-52         [-1, 64, 128, 128]               0\n","           Conv2d-53         [-1, 64, 128, 128]          36,864\n","      BatchNorm2d-54         [-1, 64, 128, 128]             128\n","             ReLU-55         [-1, 64, 128, 128]               0\n","  ConvTranspose2d-56         [-1, 32, 256, 256]           8,224\n","           Conv2d-57         [-1, 32, 256, 256]          18,432\n","      BatchNorm2d-58         [-1, 32, 256, 256]              64\n","             ReLU-59         [-1, 32, 256, 256]               0\n","           Conv2d-60         [-1, 32, 256, 256]           9,216\n","      BatchNorm2d-61         [-1, 32, 256, 256]              64\n","             ReLU-62         [-1, 32, 256, 256]               0\n","           Conv2d-63          [-1, 1, 256, 256]              33\n","================================================================\n","Total params: 7,762,465\n","Trainable params: 7,762,465\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.25\n","Forward/backward pass size (MB): 404.00\n","Params size (MB): 29.61\n","Estimated Total Size (MB): 433.86\n","----------------------------------------------------------------\n","None\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"code","metadata":{"id":"O3A2ecqdPuUt"},"source":["fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)  # Tensor를 numpy로 변환\n","fn_denorm = lambda x, mean, std: (x * std) + mean  # DeNomarlization\n","fn_class = lambda x: 1.0 * (x > 0.4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6Jy2ctTXEv_"},"source":["def load_model(ckpt_dir, model, optim):\n","    if not os.path.exists(ckpt_dir):\n","        epoch = 0\n","        return model\n","\n","    ckpt_lst = os.listdir(ckpt_dir)\n","    ckpt_lst.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n","    print(os.path.join(ckpt_dir, ckpt_lst[-1]))\n","\n","    dict_model = torch.load(os.path.join(ckpt_dir, ckpt_lst[-1]))\n","    model.load_state_dict(dict_model['model'], strict=False)\n","    optim.load_state_dict(dict_model['optim'])\n","    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n","    print(\"Get saved weights successfully.\")\n","\n","    return model, optim, epoch\n","\n","def save_model(ckpt_dir, model, optim, epoch):\n","    if not os.path.exists(ckpt_dir):\n","        os.makedirs(ckpt_dir)\n","\n","    torch.save({'model': model.state_dict(), 'optim': optim.state_dict()},\n","                \"./%s/model_epoch%d.pth\" % (ckpt_dir, epoch))\n","    print(f'>> save model_{epoch}.pth')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GxAdDAPKYbO0"},"source":["# Train & Valid"]},{"cell_type":"code","metadata":{"id":"h_i-iyqjXUa7"},"source":["def numeric_score(output, label):\n","    FP = np.float(np.sum((output == 1) & (label == 0)))\n","    FN = np.float(np.sum((output == 0) & (label == 1)))\n","    if FP != 0.0 or FN != 0.0:\n","        pass\n","    TP = np.float(np.sum((output == 1) & (label == 1)))\n","    TN = np.float(np.sum((output == 0) & (label == 0)))\n","\n","    return FP, FN, TP, TN\n","\n","def get_score(output, label):\n","    FP, FN, TP, TN = numeric_score(output, label)\n","    N = FP + FN + TP + TN\n","\n","    epsilon = 1e-6\n","\n","    # Recall : TP / TP+FN\n","    recall = np.divide(TP, TP + FN + epsilon)\n","    # Precision : TP / TP+FP\n","    precision = np.divide(TP, (TP+FP+epsilon))\n","\n","    accuracy = np.divide((TP + TN), N+epsilon)\n","\n","    # F1 socre = 2 * (A interect B) / |A| + |B| = 2TP / 2TP + FP + FN\n","    f1_score = 2 * (precision*recall) / (precision + recall + epsilon)\n","    dice_coeff = 2*TP / (2*TP+FP+FN+epsilon)\n","\n","    # J(A,B) = | A intersect B | / | A union B |\n","    jaccard_score = TP / (TP+FN+FP+ epsilon)\n","\n","    return recall * 100, precision * 100, accuracy * 100, f1_score*100, jaccard_score*100\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mp9I9Htmhdxw"},"source":["import copy\n","\n","def metric(gt,pred):\n","    preds = pred.detach().numpy()\n","    gts = gt.detach().numpy()\n","\n","    pred = preds.astype(int)  # float data does not support bit_and and bit_or\n","    gdth = gts.astype(int)  # float data does not support bit_and and bit_or\n","    fp_array = copy.deepcopy(pred)  # keep pred unchanged\n","    fn_array = copy.deepcopy(gdth)\n","    gdth_sum = np.sum(gdth)\n","    pred_sum = np.sum(pred)\n","    intersection = gdth & pred\n","    union = gdth | pred\n","    intersection_sum = np.count_nonzero(intersection)\n","    union_sum = np.count_nonzero(union)\n","\n","    tp_array = intersection\n","\n","    tmp = pred - gdth\n","    fp_array[tmp < 1] = 0\n","\n","    tmp2 = gdth - pred\n","    fn_array[tmp2 < 1] = 0\n","\n","    tn_array = np.ones(gdth.shape) - union\n","\n","    tp, fp, fn, tn = np.sum(tp_array), np.sum(fp_array), np.sum(fn_array), np.sum(tn_array)\n","\n","    smooth = 0.001\n","    precision = tp / (pred_sum + smooth)\n","    recall = tp / (gdth_sum + smooth)\n","\n","    false_positive_rate = fp / (fp + tn + smooth)\n","    false_negtive_rate = fn / (fn + tp + smooth)\n","\n","    jaccard = intersection_sum / (union_sum + smooth)\n","    dice = 2 * intersection_sum / (gdth_sum + pred_sum + smooth)\n","    \n","    epsilon = 1e-5\n","    f1_score = 2 * (precision*recall) / (precision + recall + epsilon)\n","\n","    return false_positive_rate,false_negtive_rate,f1_score\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXTEM20PBwo3"},"source":["import wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VJ0phNDwB_Wi","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1636123587124,"user_tz":-540,"elapsed":5104,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"ea320877-b063-4f7c-f397-0dde16199105"},"source":["wandb.login()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jH3Wl4nQ2rtY","executionInfo":{"status":"error","timestamp":1636144990560,"user_tz":-540,"elapsed":21403440,"user":{"displayName":"승아","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjLe0GoZZe5YdrnY6MJpIFgIzfBdXfUJ_X0tiWp=s64","userId":"08698022982440908757"}},"outputId":"06e7b38e-a7ba-4729-80b5-9a9c6ba932c6"},"source":["st_epoch = 0\n","\n","wandb.init(project='scoliosisV2', reinit=True)\n","wandb.run.name = f'UNet/{lr}/Dice'\n","wandb.config = {'learning_rate':lr, 'epochs':num_epoch, 'batch_size':batch_size}\n","wandb.watch(model)\n","\n","if train_continue:\n","  model, optim, st_epoch = load_model(ckpt_dir=ckpt_dir, model=model, optim=optim)\n","else:\n","  print(f'batch_size:{batch_size}, epoch:{num_epoch}, train_continue:{train_continue}, ckpt_dir:{ckpt_dir}, augment:{augment}')\n","\n","for epoch in range(st_epoch + 1, num_epoch + 1):\n","  model.train()  # 모델 학습 모드\n","  loss_arr = []\n","  train_f1_score = []\n","\n","\n","  for iter, data in enumerate(tqdm(train_loader), 1):\n","    # forward pass\n","    input = data['input'].to(device)\n","    label = data['label'].to(device)\n","\n","    optim.zero_grad()  # 학습 완료 후 gradients 0으로 변경\n","\n","    output = model(input)\n","\n","    loss = dsc_loss(output, label)\n","    loss.backward()\n","    optim.step()\n","\n","    _loss = loss.item()  # loss 손실값 불러오기\n","    loss_arr.append(_loss)\n","        \n","    # for metrics\n","    # logit = torch.sigmoid(output)\n","    # output = logit.clone()\n","    output[output>0.5] = 1\n","    output[output<=0.5] = 0\n","    \n","    false_positive_rate,false_negtive_rate,f1_score = metric(label.cpu(), output.cpu())\n","    train_f1_score.append(f1_score)\n","        \n","  wandb.log({\n","      \"f1-score\": np.mean(train_f1_score),\n","      \"train-iter_loss\": np.mean(loss_arr),})\n","\n","  wandb.log({\"train-loss\": np.mean(loss_arr)})\n","  print(\"TRAIN: EPOCH %04d / %04d | BATCH %04d / %04d | LOSS %.4f\" %\n","        (epoch, num_epoch, iter, num_batch_train, np.mean(loss_arr)))\n","  \n","  #validation\n","  with torch.no_grad():\n","    model.eval()\n","    loss_arr = []\n","    total_f1_score = []\n","\n","    for iter, data in enumerate(tqdm(val_loader), 1):\n","      # forward pass\n","      input = data['input'].to(device)\n","      label = data['label'].to(device)\n","\n","      output = model(input)\n","\n","      loss = dsc_loss(output, label)\n","      loss_arr += [loss.item()]\n","      \n","      # for metrics\n","      # logit = torch.sigmoid(output)\n","      # output = logit.clone()\n","      output[output>0.5] = 1\n","      output[output<=0.5] = 0\n","      \n","      # save_predictedMask(input, label, output)\n","  \n","      false_positive_rate,false_negtive_rate,f1_score = metric(label.cpu(), output.cpu())\n","      total_f1_score.append(f1_score)\n","    \n","    wandb.log({\"val-loss\": np.mean(loss_arr)})\n","      \n","    wandb.log({\n","        \"val/f1-score\": np.array(total_f1_score).mean(),\n","        \"val-loss\": np.mean(loss_arr)})\n","\n","  if epoch % 5 == 0:\n","    save_model(ckpt_dir=ckpt_dir, model=model, optim=optim, epoch=epoch)\n","    print(f'saved model, {np.mean(loss_arr)}')\n","  \n","train_writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnepersica\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/nepersica/scoliosisV2/runs/1i76jq6u\" target=\"_blank\">divine-violet-33</a></strong> to <a href=\"https://wandb.ai/nepersica/scoliosisV2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["batch_size:8, epoch:100, train_continue:False, ckpt_dir:이승아/checkpoint/U-Net/Dice/1e-05(padding), augment:True\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [31:03<00:00,  8.00s/it]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0001 / 0100 | BATCH 0233 / 0030 | LOSS 0.7949\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [04:03<00:00,  8.10s/it]\n","100%|██████████| 233/233 [02:46<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0002 / 0100 | BATCH 0233 / 0030 | LOSS 0.7174\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0003 / 0100 | BATCH 0233 / 0030 | LOSS 0.6951\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n","100%|██████████| 233/233 [02:46<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0004 / 0100 | BATCH 0233 / 0030 | LOSS 0.6874\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0005 / 0100 | BATCH 0233 / 0030 | LOSS 0.6810\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_5.pth\n","saved model, 0.680637530485789\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0006 / 0100 | BATCH 0233 / 0030 | LOSS 0.6736\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0007 / 0100 | BATCH 0233 / 0030 | LOSS 0.6686\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0008 / 0100 | BATCH 0233 / 0030 | LOSS 0.6626\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0009 / 0100 | BATCH 0233 / 0030 | LOSS 0.6579\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0010 / 0100 | BATCH 0233 / 0030 | LOSS 0.6505\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_10.pth\n","saved model, 0.6449123958746592\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0011 / 0100 | BATCH 0233 / 0030 | LOSS 0.6458\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0012 / 0100 | BATCH 0233 / 0030 | LOSS 0.6411\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0013 / 0100 | BATCH 0233 / 0030 | LOSS 0.6331\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0014 / 0100 | BATCH 0233 / 0030 | LOSS 0.6294\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0015 / 0100 | BATCH 0233 / 0030 | LOSS 0.6232\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_15.pth\n","saved model, 0.6203757703304291\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0016 / 0100 | BATCH 0233 / 0030 | LOSS 0.6193\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0017 / 0100 | BATCH 0233 / 0030 | LOSS 0.6114\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0018 / 0100 | BATCH 0233 / 0030 | LOSS 0.6059\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0019 / 0100 | BATCH 0233 / 0030 | LOSS 0.5997\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0020 / 0100 | BATCH 0233 / 0030 | LOSS 0.5930\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_20.pth\n","saved model, 0.5931437611579895\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0021 / 0100 | BATCH 0233 / 0030 | LOSS 0.5887\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0022 / 0100 | BATCH 0233 / 0030 | LOSS 0.5839\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0023 / 0100 | BATCH 0233 / 0030 | LOSS 0.5763\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0024 / 0100 | BATCH 0233 / 0030 | LOSS 0.5699\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0025 / 0100 | BATCH 0233 / 0030 | LOSS 0.5635\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_25.pth\n","saved model, 0.5661779463291168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0026 / 0100 | BATCH 0233 / 0030 | LOSS 0.5592\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0027 / 0100 | BATCH 0233 / 0030 | LOSS 0.5512\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0028 / 0100 | BATCH 0233 / 0030 | LOSS 0.5436\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0029 / 0100 | BATCH 0233 / 0030 | LOSS 0.5384\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0030 / 0100 | BATCH 0233 / 0030 | LOSS 0.5316\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_30.pth\n","saved model, 0.5285572071870168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:49<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0031 / 0100 | BATCH 0233 / 0030 | LOSS 0.5243\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0032 / 0100 | BATCH 0233 / 0030 | LOSS 0.5181\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0033 / 0100 | BATCH 0233 / 0030 | LOSS 0.5121\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0034 / 0100 | BATCH 0233 / 0030 | LOSS 0.5059\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0035 / 0100 | BATCH 0233 / 0030 | LOSS 0.4979\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_35.pth\n","saved model, 0.49981064001719155\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0036 / 0100 | BATCH 0233 / 0030 | LOSS 0.4903\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.30it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0037 / 0100 | BATCH 0233 / 0030 | LOSS 0.4854\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n","100%|██████████| 233/233 [02:47<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0038 / 0100 | BATCH 0233 / 0030 | LOSS 0.4766\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0039 / 0100 | BATCH 0233 / 0030 | LOSS 0.4739\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0040 / 0100 | BATCH 0233 / 0030 | LOSS 0.4652\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_40.pth\n","saved model, 0.47188467582066856\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0041 / 0100 | BATCH 0233 / 0030 | LOSS 0.4580\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0042 / 0100 | BATCH 0233 / 0030 | LOSS 0.4501\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0043 / 0100 | BATCH 0233 / 0030 | LOSS 0.4445\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0044 / 0100 | BATCH 0233 / 0030 | LOSS 0.4365\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:50<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0045 / 0100 | BATCH 0233 / 0030 | LOSS 0.4303\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_45.pth\n","saved model, 0.42849056522051493\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:49<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0046 / 0100 | BATCH 0233 / 0030 | LOSS 0.4232\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n","100%|██████████| 233/233 [02:50<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0047 / 0100 | BATCH 0233 / 0030 | LOSS 0.4150\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n","100%|██████████| 233/233 [02:49<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0048 / 0100 | BATCH 0233 / 0030 | LOSS 0.4107\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:48<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0049 / 0100 | BATCH 0233 / 0030 | LOSS 0.4025\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0050 / 0100 | BATCH 0233 / 0030 | LOSS 0.3950\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_50.pth\n","saved model, 0.3978434443473816\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0051 / 0100 | BATCH 0233 / 0030 | LOSS 0.3895\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0052 / 0100 | BATCH 0233 / 0030 | LOSS 0.3823\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0053 / 0100 | BATCH 0233 / 0030 | LOSS 0.3729\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0054 / 0100 | BATCH 0233 / 0030 | LOSS 0.3674\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:50<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0055 / 0100 | BATCH 0233 / 0030 | LOSS 0.3618\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_55.pth\n","saved model, 0.3659690777460734\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:50<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0056 / 0100 | BATCH 0233 / 0030 | LOSS 0.3547\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0057 / 0100 | BATCH 0233 / 0030 | LOSS 0.3493\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:50<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0058 / 0100 | BATCH 0233 / 0030 | LOSS 0.3418\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0059 / 0100 | BATCH 0233 / 0030 | LOSS 0.3335\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0060 / 0100 | BATCH 0233 / 0030 | LOSS 0.3281\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_60.pth\n","saved model, 0.3316022018591563\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0061 / 0100 | BATCH 0233 / 0030 | LOSS 0.3221\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0062 / 0100 | BATCH 0233 / 0030 | LOSS 0.3165\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0063 / 0100 | BATCH 0233 / 0030 | LOSS 0.3079\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0064 / 0100 | BATCH 0233 / 0030 | LOSS 0.3042\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0065 / 0100 | BATCH 0233 / 0030 | LOSS 0.2973\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_65.pth\n","saved model, 0.3013473232587179\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0066 / 0100 | BATCH 0233 / 0030 | LOSS 0.2912\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0067 / 0100 | BATCH 0233 / 0030 | LOSS 0.2845\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0068 / 0100 | BATCH 0233 / 0030 | LOSS 0.2795\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0069 / 0100 | BATCH 0233 / 0030 | LOSS 0.2741\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0070 / 0100 | BATCH 0233 / 0030 | LOSS 0.2676\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_70.pth\n","saved model, 0.26956017017364503\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0071 / 0100 | BATCH 0233 / 0030 | LOSS 0.2621\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.22it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0072 / 0100 | BATCH 0233 / 0030 | LOSS 0.2557\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0073 / 0100 | BATCH 0233 / 0030 | LOSS 0.2491\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0074 / 0100 | BATCH 0233 / 0030 | LOSS 0.2466\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.27it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0075 / 0100 | BATCH 0233 / 0030 | LOSS 0.2407\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_75.pth\n","saved model, 0.2534602721532186\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0076 / 0100 | BATCH 0233 / 0030 | LOSS 0.2353\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0077 / 0100 | BATCH 0233 / 0030 | LOSS 0.2309\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0078 / 0100 | BATCH 0233 / 0030 | LOSS 0.2257\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:50<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0079 / 0100 | BATCH 0233 / 0030 | LOSS 0.2201\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0080 / 0100 | BATCH 0233 / 0030 | LOSS 0.2158\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_80.pth\n","saved model, 0.22408260703086852\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0081 / 0100 | BATCH 0233 / 0030 | LOSS 0.2109\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0082 / 0100 | BATCH 0233 / 0030 | LOSS 0.2057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0083 / 0100 | BATCH 0233 / 0030 | LOSS 0.2020\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0084 / 0100 | BATCH 0233 / 0030 | LOSS 0.1982\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.25it/s]\n","100%|██████████| 233/233 [02:51<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0085 / 0100 | BATCH 0233 / 0030 | LOSS 0.1921\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_85.pth\n","saved model, 0.20113932887713115\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0086 / 0100 | BATCH 0233 / 0030 | LOSS 0.1903\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0087 / 0100 | BATCH 0233 / 0030 | LOSS 0.1842\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0088 / 0100 | BATCH 0233 / 0030 | LOSS 0.1809\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.21it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0089 / 0100 | BATCH 0233 / 0030 | LOSS 0.1775\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0090 / 0100 | BATCH 0233 / 0030 | LOSS 0.1737\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_90.pth\n","saved model, 0.1826540450255076\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:54<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0091 / 0100 | BATCH 0233 / 0030 | LOSS 0.1685\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0092 / 0100 | BATCH 0233 / 0030 | LOSS 0.1664\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.22it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0093 / 0100 | BATCH 0233 / 0030 | LOSS 0.1624\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:23<00:00,  1.26it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0094 / 0100 | BATCH 0233 / 0030 | LOSS 0.1597\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:54<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0095 / 0100 | BATCH 0233 / 0030 | LOSS 0.1543\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_95.pth\n","saved model, 0.173475315173467\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0096 / 0100 | BATCH 0233 / 0030 | LOSS 0.1529\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0097 / 0100 | BATCH 0233 / 0030 | LOSS 0.1499\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.23it/s]\n","100%|██████████| 233/233 [02:52<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0098 / 0100 | BATCH 0233 / 0030 | LOSS 0.1458\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.22it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0099 / 0100 | BATCH 0233 / 0030 | LOSS 0.1443\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.24it/s]\n","100%|██████████| 233/233 [02:53<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["TRAIN: EPOCH 0100 / 0100 | BATCH 0233 / 0030 | LOSS 0.1407\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 30/30 [00:24<00:00,  1.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":[">> save model_100.pth\n","saved model, 0.15239123503367105\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-86379dc0c92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'saved model, {np.mean(loss_arr)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_writer' is not defined"]}]}]}